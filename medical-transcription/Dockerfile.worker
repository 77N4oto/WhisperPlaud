# WhisperX Transcription Worker with CUDA Support
# Based on NVIDIA CUDA official image
FROM nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu22.04

# Set environment variables
ENV DEBIAN_FRONTEND=noninteractive \
    PYTHONUNBUFFERED=1 \
    PYTHONPATH=/app \
    CUDA_HOME=/usr/local/cuda \
    PATH=/usr/local/cuda/bin:$PATH \
    LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH

# Install system dependencies
RUN apt-get update && apt-get install -y \
    python3.11 \
    python3-pip \
    ffmpeg \
    git \
    wget \
    && rm -rf /var/lib/apt/lists/*

# Create working directory
WORKDIR /app

# Copy requirements first for better caching
COPY requirements-worker.txt .

# Install Python dependencies
# Note: torch with CUDA support will be installed via requirements-worker.txt
RUN pip3 install --no-cache-dir --upgrade pip && \
    pip3 install --no-cache-dir -r requirements-worker.txt

# Copy worker code and medical dictionary
COPY src/workers/transcription_worker.py ./workers/
COPY medical_dictionary.json .

# Create non-root user for security
RUN useradd -m -u 1000 worker && \
    chown -R worker:worker /app

USER worker

# Health check - verify GPU and Redis connectivity
HEALTHCHECK --interval=30s --timeout=10s --start-period=120s \
    CMD python3 -c "import torch; import redis; assert torch.cuda.is_available(), 'CUDA not available'; print('OK')" || exit 1

# Run the worker
CMD ["python3", "workers/transcription_worker.py"]
