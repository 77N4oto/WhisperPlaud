# WhisperX ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¬ã‚¤ãƒ‰

ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ã€WhisperXã‚’ä½¿ç”¨ã—ãŸæ–‡å­—èµ·ã“ã—ãƒ¯ãƒ¼ã‚«ãƒ¼ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é †ã‚’èª¬æ˜ã—ã¾ã™ã€‚

---

## ğŸ“‹ ã‚·ã‚¹ãƒ†ãƒ è¦ä»¶

### å¿…é ˆ
- **NVIDIA GPU** - CUDA 11.8ä»¥é™å¯¾å¿œ
- **VRAM** - 6GBä»¥ä¸Šæ¨å¥¨ï¼ˆæœ€ä½4GBï¼‰
- **OS** - Windows 10/11
- **Python** - 3.11ä»¥é™
- **FFmpeg** - ã‚·ã‚¹ãƒ†ãƒ ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿

### æ¨å¥¨ã‚¹ãƒšãƒƒã‚¯
- **GPU**: NVIDIA RTX 3060 (12GB VRAM) ä»¥ä¸Š
- **RAM**: 16GBä»¥ä¸Š
- **ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸**: 10GBä»¥ä¸Šã®ç©ºãå®¹é‡ï¼ˆãƒ¢ãƒ‡ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ï¼‰

---

## ğŸ”§ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é †

### Step 1: CUDA Toolkitã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

1. NVIDIAå…¬å¼ã‚µã‚¤ãƒˆã‹ã‚‰CUDA Toolkit 11.8ä»¥é™ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
   - https://developer.nvidia.com/cuda-downloads

2. ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ©ãƒ¼ã‚’å®Ÿè¡Œã—ã¦CUDAã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

3. ç’°å¢ƒå¤‰æ•°ã®ç¢ºèªï¼ˆPowerShellã§å®Ÿè¡Œï¼‰
   ```powershell
   nvcc --version
   ```
   
   CUDAãƒãƒ¼ã‚¸ãƒ§ãƒ³ãŒè¡¨ç¤ºã•ã‚Œã‚Œã°OK

---

### Step 2: FFmpegã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

PowerShellã§ä»¥ä¸‹ã‚’å®Ÿè¡Œï¼š

```powershell
# wingetã‚’ä½¿ç”¨ï¼ˆWindows 11 / Windows 10 æœ€æ–°ç‰ˆï¼‰
winget install ffmpeg

# ã¾ãŸã¯ã€Chocolateyã‚’ä½¿ç”¨
choco install ffmpeg

# ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ç¢ºèª
ffmpeg -version
```

---

### Step 3: Hugging Face Token ã®å–å¾—

WhisperXã®è©±è€…åˆ†é›¢æ©Ÿèƒ½ï¼ˆpyannote.audioï¼‰ã«ã¯ã€Hugging Face TokenãŒå¿…è¦ã§ã™ã€‚

1. Hugging Faceã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’ä½œæˆï¼ˆç„¡æ–™ï¼‰
   - https://huggingface.co/join

2. Tokenã‚’ç”Ÿæˆ
   - https://huggingface.co/settings/tokens
   - "New token" ã‚’ã‚¯ãƒªãƒƒã‚¯
   - Name: `whisperplaud-worker`
   - Role: `read` ï¼ˆèª­ã¿å–ã‚Šå°‚ç”¨ã§OKï¼‰
   - "Generate a token" ã‚’ã‚¯ãƒªãƒƒã‚¯

3. Tokenã‚’ã‚³ãƒ”ãƒ¼ï¼ˆ`hf_xxxxxxxxxxxxxxxxxxxxx` ã®å½¢å¼ï¼‰

---

### Step 4: ç’°å¢ƒå¤‰æ•°ã®è¨­å®š

`.env.local` ãƒ•ã‚¡ã‚¤ãƒ«ã«ä»¥ä¸‹ã‚’è¿½åŠ ï¼š

```bash
# Hugging Face Token
HF_TOKEN=hf_xxxxxxxxxxxxxxxxxxxxx

# WhisperXè¨­å®šï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
WHISPER_MODEL_SIZE=large-v2  # ã¾ãŸã¯ large-v3
WHISPER_DEVICE=auto          # è‡ªå‹•ã§CUDAã‚’ä½¿ç”¨
```

---

### Step 5: Pythonä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```powershell
# ä»®æƒ³ç’°å¢ƒã®ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ãƒˆ
.\whisper-pyannote-env\Scripts\Activate.ps1

# WhisperXã¨ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install -r medical-transcription/requirements-worker.txt

# GPUç¢ºèª
python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}'); print(f'GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"None\"}')"
```

**æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›**:
```
CUDA available: True
GPU: NVIDIA GeForce RTX 3060
```

---

### Step 6: å‹•ä½œç¢ºèª

```powershell
# Pythonãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’èµ·å‹•
python medical-transcription/src/workers/transcription_worker.py
```

**æ­£å¸¸èµ·å‹•ã®å ´åˆ**:
```
[Worker] Loaded .env.local from: ...
Connected to Redis: redis://localhost:6379
Connected to S3: http://localhost:9000
Using device: cuda
CUDA available: True
GPU: NVIDIA GeForce RTX 3060
VRAM: 12.0 GB
Loaded 10 medical terms
Worker initialization complete
Worker is ready and listening for jobs...
Subscribed to Redis channel: job:new
Waiting for transcription jobs...
```

---

## ğŸš¨ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### GPU/CUDAãŒèªè­˜ã•ã‚Œãªã„

```powershell
# CUDAã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ç¢ºèª
nvcc --version

# PyTorchã®CUDAå¯¾å¿œç¢ºèª
python -c "import torch; print(torch.version.cuda)"

# å†ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆCUDA 11.8ç”¨ï¼‰
pip uninstall torch torchaudio
pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu118
```

### FFmpegãŒè¦‹ã¤ã‹ã‚‰ãªã„

```powershell
# FFmpegã®ãƒ‘ã‚¹ç¢ºèª
where.exe ffmpeg

# ç’°å¢ƒå¤‰æ•°PATHã«è¿½åŠ ï¼ˆã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ â†’ ç’°å¢ƒå¤‰æ•°ï¼‰
```

### Hugging Face Token ã‚¨ãƒ©ãƒ¼

```
ValueError: HF_TOKEN not set
```

â†’ `.env.local` ã« `HF_TOKEN=hf_xxx...` ã‚’è¿½åŠ ã—ã¦ãã ã•ã„

### VRAMä¸è¶³ã‚¨ãƒ©ãƒ¼

```
RuntimeError: CUDA out of memory
```

â†’ ã‚ˆã‚Šå°ã•ã„ãƒ¢ãƒ‡ãƒ«ã«å¤‰æ›´ï¼š
```bash
WHISPER_MODEL_SIZE=medium  # ã¾ãŸã¯ small
```

---

## ğŸ“Š ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã¨VRAMè¦ä»¶

| ãƒ¢ãƒ‡ãƒ« | VRAMå¿…è¦é‡ | ç²¾åº¦ | å‡¦ç†é€Ÿåº¦ |
|--------|-----------|------|---------|
| small  | 2-3GB     | ä¸­   | é€Ÿã„    |
| medium | 4-5GB     | é«˜   | æ™®é€š    |
| large-v2 | 6-8GB   | æœ€é«˜ | ã‚„ã‚„é…ã„ |
| large-v3 | 6-8GB   | æœ€é«˜ | ã‚„ã‚„é…ã„ |

**æ¨å¥¨**: `large-v2`ï¼ˆç²¾åº¦ã¨é€Ÿåº¦ã®ãƒãƒ©ãƒ³ã‚¹ãŒè‰¯ã„ï¼‰

---

## ğŸ¯ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

1. âœ… WhisperXã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†
2. âœ… ãƒ¯ãƒ¼ã‚«ãƒ¼èµ·å‹•ç¢ºèª
3. â­ï¸ Webã‚¢ãƒ—ãƒªã‹ã‚‰éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãƒ†ã‚¹ãƒˆ
4. â­ï¸ æ–‡å­—èµ·ã“ã—çµæœã¨è©±è€…åˆ†é›¢ã‚’ç¢ºèª

---

## ğŸ“š å‚è€ƒãƒªãƒ³ã‚¯

- **WhisperX GitHub**: https://github.com/m-bain/whisperX
- **pyannote.audio**: https://github.com/pyannote/pyannote-audio
- **CUDA Toolkit**: https://developer.nvidia.com/cuda-toolkit
- **Hugging Face**: https://huggingface.co/

---

**ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†å¾Œã¯ã€`docs/HANDOFF.md` ã®ã€Œæ¬¡ã®æ‰‹ã€ã«å¾“ã£ã¦é–‹ç™ºã‚’é€²ã‚ã¦ãã ã•ã„ï¼**

