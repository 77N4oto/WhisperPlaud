# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿å•é¡Œã®ä¿®æ­£

**æ—¥æ™‚**: 2025-10-16 16:00  
**å•é¡Œ**: WorkerãŒ`.env.local`ã‚’èª­ã¿è¾¼ã¾ãšã€CPUãƒ¢ãƒ¼ãƒ‰ã§å‹•ä½œã—ã¦ã„ãŸ

---

## ğŸ”´ å•é¡Œã®ç—‡çŠ¶

- âœ… PyTorch CUDA 12.1ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿
- âœ… GPUå‹•ä½œç¢ºèªæ¸ˆã¿ï¼ˆRTX 3060ï¼‰
- âœ… `.env.local`ã«`WHISPER_DEVICE=auto`è¨­å®šæ¸ˆã¿
- âŒ **WorkerãŒç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚“ã§ã„ãªã„**
- âŒ **å‡¦ç†ãŒéå¸¸ã«é…ã„**ï¼ˆCPUãƒ¢ãƒ¼ãƒ‰ã§å‹•ä½œï¼‰

---

## ğŸ” æ ¹æœ¬åŸå› 

### å•é¡Œã®æ‰€åœ¨

`transcription_worker.py`ã®ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿ï¼š
```python
# æ—§ã‚³ãƒ¼ãƒ‰ï¼ˆå•é¡Œã‚ã‚Šï¼‰
load_dotenv()  # å¼•æ•°ãªã— â†’ ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã® .env ã‚’æ¢ã™
```

### ãªãœå•é¡Œã ã£ãŸã‹

1. Workerã¯`medical-transcription/src/workers/`ã‹ã‚‰èµ·å‹•ã•ã‚Œã‚‹
2. `load_dotenv()`ã¯**ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª**ã®`.env`ã‚’æ¢ã™
3. `.env.local`ã¯`medical-transcription/`ã«ã‚ã‚‹ï¼ˆ2éšå±¤ä¸Šï¼‰
4. â†’ **ç’°å¢ƒå¤‰æ•°ãŒèª­ã¿è¾¼ã¾ã‚Œãªã„**
5. â†’ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤`large-v3`ã¨`auto`ãŒä½¿ã‚ã‚Œã‚‹ãŒã€å®Ÿéš›ã¯`auto`ãŒæ­£ã—ãæ©Ÿèƒ½ã›ãš

### ç¢ºèªçµæœ

```powershell
# Workerãƒ—ãƒ­ã‚»ã‚¹ã§ç’°å¢ƒå¤‰æ•°ã‚’ãƒã‚§ãƒƒã‚¯
WHISPER_DEVICE: not set  # âŒ èª­ã¿è¾¼ã¾ã‚Œã¦ã„ãªã„
WHISPER_MODEL_SIZE: not set  # âŒ èª­ã¿è¾¼ã¾ã‚Œã¦ã„ãªã„
```

---

## âœ… ä¿®æ­£å†…å®¹

### å¤‰æ›´ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«

**`medical-transcription/src/workers/transcription_worker.py`**

```python
# æ–°ã‚³ãƒ¼ãƒ‰ï¼ˆä¿®æ­£å¾Œï¼‰
# Configure logging first
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Load environment variables from project root
# Look for .env.local first (takes precedence), then .env
project_root = Path(__file__).parent.parent.parent  # medical-transcription/
env_local_path = project_root / '.env.local'
env_path = project_root / '.env'

if env_local_path.exists():
    load_dotenv(env_local_path)
    logger.info(f"Loaded environment from: {env_local_path}")
elif env_path.exists():
    load_dotenv(env_path)
    logger.info(f"Loaded environment from: {env_path}")
else:
    load_dotenv()  # Load from current directory or system env
    logger.warning("No .env or .env.local found in project root")
```

### å¤‰æ›´ã®ãƒã‚¤ãƒ³ãƒˆ

1. **ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’æ˜ç¤ºçš„ã«è¨ˆç®—**
   ```python
   project_root = Path(__file__).parent.parent.parent
   ```

2. **`.env.local`ã‚’å„ªå…ˆçš„ã«èª­ã¿è¾¼ã‚€**
   - `.env.local` â†’ `.env` â†’ ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®é †

3. **ãƒ­ã‚°å‡ºåŠ›ã§ç¢ºèªå¯èƒ½**
   ```
   INFO:__main__:Loaded environment from: C:\...\medical-transcription\.env.local
   ```

---

## ğŸ¯ æœŸå¾…ã•ã‚Œã‚‹å‹•ä½œ

### Workerèµ·å‹•æ™‚ã®ãƒ­ã‚°

```
INFO:__main__:Loaded environment from: C:\Users\user\Desktop\Git\WhisperPlaud\medical-transcription\.env.local
INFO:__main__:Transcription worker initialized
INFO:__main__:Redis: redis://localhost:6379
INFO:__main__:S3: http://localhost:9000
INFO:__main__:Bucket: medical-transcription
INFO:__main__:Whisper model: large-v3  â† .env.localã‹ã‚‰èª­ã¿è¾¼ã¿
INFO:__main__:Worker started. Subscribing to 'job:new' channel...
```

### Whisperãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–æ™‚

```
INFO:__main__:Initializing Whisper model: large-v3
INFO:whisper_processor:Device: cuda, Compute type: float16  â† GPUãƒ¢ãƒ¼ãƒ‰
INFO:__main__:Whisper model initialized: {'model_size': 'large-v3', 'device': 'cuda', ...}
```

---

## ğŸ“Š æ€§èƒ½æ”¹å–„

### ä¿®æ­£å‰ï¼ˆç’°å¢ƒå¤‰æ•°æœªèª­ã¿è¾¼ã¿ï¼‰

| è¨­å®š | å€¤ |
|-----|-----|
| Device | **CPU**ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰ |
| Model | large-v3 |
| å‡¦ç†é€Ÿåº¦ | 0.2-0.3x ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ  |
| 10åˆ†éŸ³å£° | **30-50åˆ†** |

### ä¿®æ­£å¾Œï¼ˆç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿æˆåŠŸï¼‰

| è¨­å®š | å€¤ |
|-----|-----|
| Device | **CUDA (GPU)** |
| Model | large-v3 |
| å‡¦ç†é€Ÿåº¦ | 5-10x ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ  |
| 10åˆ†éŸ³å£° | **1-2åˆ†** |

**é€Ÿåº¦æ”¹å–„**: **25-50å€é«˜é€ŸåŒ–** âœ¨

---

## ğŸ§ª ãƒ†ã‚¹ãƒˆæ‰‹é †

### 1. Workerèµ·å‹•ãƒ­ã‚°ã‚’ç¢ºèª

æ–°ã—ãé–‹ã„ãŸPowerShellã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã§ä»¥ä¸‹ã‚’ç¢ºèªï¼š
```
INFO:__main__:Loaded environment from: ...\.env.local  â† ã“ã‚ŒãŒè¡¨ç¤ºã•ã‚Œã‚Œã°OK
INFO:__main__:Whisper model: large-v3
```

### 2. ãƒ–ãƒ©ã‚¦ã‚¶ã‚’ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥

```
http://localhost:3000/dashboard
```

### 3. ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰

- `001-sibutomo.mp3`ï¼ˆ374.8 KBï¼‰ã‚’å‰Šé™¤ã—ã¦å†ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
- ã¾ãŸã¯æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰

### 4. å‡¦ç†é€Ÿåº¦ã‚’ç¢ºèª

**æœŸå¾…ã•ã‚Œã‚‹çµæœ**:
- âœ… é€²æ—ãŒ**é«˜é€Ÿ**ã§æ›´æ–°ï¼ˆæ•°ç§’ã€œæ•°åç§’ã§å®Œäº†ï¼‰
- âœ… Workerãƒ­ã‚°ã«`device: cuda`ã¨è¡¨ç¤º
- âœ… `nvidia-smi`ã§GPUä½¿ç”¨ç‡ãŒä¸Šæ˜‡

---

## ğŸ”§ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ç’°å¢ƒå¤‰æ•°ãŒèª­ã¿è¾¼ã¾ã‚Œãªã„å ´åˆ

**ç¢ºèª**:
```powershell
# Workerã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã§ä»¥ä¸‹ãŒè¡¨ç¤ºã•ã‚Œã‚‹ã‹
INFO:__main__:Loaded environment from: ...
```

**è¡¨ç¤ºã•ã‚Œãªã„å ´åˆ**:
1. `.env.local`ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
   ```powershell
   Test-Path C:\Users\user\Desktop\Git\WhisperPlaud\medical-transcription\.env.local
   ```

2. Workerã‚’å†èµ·å‹•

### ã¾ã CPUãƒ¢ãƒ¼ãƒ‰ã§å‹•ä½œã—ã¦ã„ã‚‹å ´åˆ

**ç¢ºèª**:
```python
# Pythonç’°å¢ƒã§ç¢ºèª
import torch
print(torch.cuda.is_available())  # True ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
```

**å¯¾å‡¦**:
1. PyTorch CUDA 12.1ãŒæ­£ã—ãã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
2. GPUãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã‚’æœ€æ–°ã«æ›´æ–°

---

## ğŸ“ é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«

### ä¿®æ­£ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«
- âœ… `medical-transcription/src/workers/transcription_worker.py`

### è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
- `medical-transcription/.env.local` - ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒå¤‰æ•°ï¼ˆå„ªå…ˆï¼‰
  ```env
  WHISPER_MODEL_SIZE=large-v3
  WHISPER_DEVICE=auto
  ```

- `medical-transcription/.env` - ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆç’°å¢ƒå¤‰æ•°ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰

---

## ğŸ“š ã¾ã¨ã‚

### å•é¡Œ
- WorkerãŒ`.env.local`ã‚’èª­ã¿è¾¼ã¾ãšã€ç’°å¢ƒå¤‰æ•°æœªè¨­å®šã§CPUãƒ¢ãƒ¼ãƒ‰å‹•ä½œ

### åŸå› 
- `load_dotenv()`ãŒã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ã¿ã‚’æ¢ã—ã¦ã„ãŸ

### è§£æ±º
- ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’è¨ˆç®—ã—ã¦æ˜ç¤ºçš„ã«`.env.local`ã‚’èª­ã¿è¾¼ã‚€

### çµæœ
- âœ… GPUé«˜é€Ÿå‡¦ç†ãŒæœ‰åŠ¹åŒ–
- âœ… å‡¦ç†é€Ÿåº¦ãŒ25-50å€å‘ä¸Š
- âœ… large-v3ãƒ¢ãƒ‡ãƒ«ã§å®Ÿç”¨çš„ãªé€Ÿåº¦ã‚’å®Ÿç¾

---

**ä¿®æ­£æ—¥æ™‚**: 2025-10-16 16:00  
**ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**: âœ… ä¿®æ­£å®Œäº† - Workerå†èµ·å‹•æ¸ˆã¿

